{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "559d8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import random as r\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "froot = './motifSimulator'\n",
    "\n",
    "df = pd.read_csv(froot + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8a9d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = 'ACGT'\n",
    "NALPH = len(ALPHABET)\n",
    "INVALPH = [-1] * ord('Z')\n",
    "for i, char in enumerate(ALPHABET):\n",
    "    INVALPH[ord(char)] = i\n",
    "        \n",
    "def seq_to_one_hot(seq):\n",
    "    seqlen = len(seq)\n",
    "    res = np.zeros(NALPH * seqlen, dtype=np.uint8)    \n",
    "    arr = np.array(list(seq))\n",
    "    for j, c in enumerate(arr):\n",
    "        res[NALPH*j + INVALPH[ord(c)]] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10a9bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# first convert all sequences to one-hot representation\n",
    "# also convert both features and labels to tensors\n",
    "feat = torch.Tensor(np.array(list(map(seq_to_one_hot, df['seq']))))  # is there a simpler way?\n",
    "labl = torch.Tensor(df['hasMotif']).to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37773029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test, and validation sets\n",
    "import torch.utils.data as td\n",
    "allset = TensorDataset(feat, labl)\n",
    "trnset, valset, tstset = td.random_split(allset, [0.5,0.25,0.25])\n",
    "\n",
    "# set up data loaders\n",
    "trndl = DataLoader(trnset, batch_size=8, shuffle=True)\n",
    "tstdl = DataLoader(tstset, batch_size=8, shuffle=True)\n",
    "valdl = DataLoader(valset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8f1446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv1d(1, 8, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=21, stride=21, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(8, 8, kernel_size=(10,), stride=(1,), padding=(2,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=80, out_features=2, bias=True)\n",
      "  (fc1): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# set up the model\n",
    "import torch.nn as nn\n",
    "\n",
    "# this model is slightly adapted from an image-processing CNN in \n",
    "#\"Machine Learning with PyTorch and Scikit-Learn\", Raschka et al.\n",
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv1d(\n",
    "        in_channels=1, out_channels=8,\n",
    "        kernel_size=21, padding=10\n",
    "    )\n",
    ")\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool1d(kernel_size=21))\n",
    "model.add_module(\n",
    "    'conv2',\n",
    "    nn.Conv1d(\n",
    "        in_channels=8, out_channels=8,\n",
    "        kernel_size=10, padding=2\n",
    "    )\n",
    ")\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('pool2', nn.MaxPool1d(kernel_size=5))\n",
    "\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "model.add_module('linear', nn.Linear(80,2))\n",
    "model.add_module('fc1', nn.Softmax(dim=1))\n",
    "\n",
    "# check model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bc0bef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((8,1,1200))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a98a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d1965cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            # have to fix dimensionality\n",
    "            x_batch_sz = x_batch.size()[0]\n",
    "            x_batch_re = torch.reshape(x_batch, (x_batch_sz, 1, 1200))\n",
    "            pred = model(x_batch_re)    \n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "            \n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                # have to fix dimensionality\n",
    "                x_batch_sz = x_batch.size()[0]\n",
    "                x_batch_re = torch.reshape(x_batch, (x_batch_sz, 1, 1200))\n",
    "                pred = model(x_batch_re)    \n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0)\n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "                \n",
    "            loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "            accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "            \n",
    "        print(f'Epoch {epoch+1} accuracy: '\n",
    "              f'{accuracy_hist_train[epoch]:.4f} val_accuracy: '\n",
    "              f'{accuracy_hist_valid[epoch]:.4f}')\n",
    "        \n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2456915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 1 accuracy: 0.6190 val_accuracy: 0.7387\n",
      "Epoch 2\n",
      "Epoch 2 accuracy: 0.8260 val_accuracy: 0.8451\n",
      "Epoch 3\n",
      "Epoch 3 accuracy: 0.8636 val_accuracy: 0.8751\n",
      "Epoch 4\n",
      "Epoch 4 accuracy: 0.8831 val_accuracy: 0.8805\n",
      "Epoch 5\n",
      "Epoch 5 accuracy: 0.8949 val_accuracy: 0.8909\n",
      "Epoch 6\n",
      "Epoch 6 accuracy: 0.9010 val_accuracy: 0.9061\n",
      "Epoch 7\n",
      "Epoch 7 accuracy: 0.9071 val_accuracy: 0.9053\n",
      "Epoch 8\n",
      "Epoch 8 accuracy: 0.9089 val_accuracy: 0.9015\n",
      "Epoch 9\n",
      "Epoch 9 accuracy: 0.9122 val_accuracy: 0.9181\n",
      "Epoch 10\n",
      "Epoch 10 accuracy: 0.9147 val_accuracy: 0.9199\n",
      "Epoch 11\n",
      "Epoch 11 accuracy: 0.9164 val_accuracy: 0.9199\n",
      "Epoch 12\n",
      "Epoch 12 accuracy: 0.9203 val_accuracy: 0.9181\n",
      "Epoch 13\n",
      "Epoch 13 accuracy: 0.9221 val_accuracy: 0.9179\n",
      "Epoch 14\n",
      "Epoch 14 accuracy: 0.9244 val_accuracy: 0.9240\n",
      "Epoch 15\n",
      "Epoch 15 accuracy: 0.9248 val_accuracy: 0.9233\n",
      "Epoch 16\n",
      "Epoch 16 accuracy: 0.9262 val_accuracy: 0.9221\n",
      "Epoch 17\n",
      "Epoch 17 accuracy: 0.9304 val_accuracy: 0.9252\n",
      "Epoch 18\n",
      "Epoch 18 accuracy: 0.9301 val_accuracy: 0.9268\n",
      "Epoch 19\n",
      "Epoch 19 accuracy: 0.9314 val_accuracy: 0.9256\n",
      "Epoch 20\n",
      "Epoch 20 accuracy: 0.9313 val_accuracy: 0.9262\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, trndl, valdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9772956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
