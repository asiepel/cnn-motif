{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ba1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as td\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import math\n",
    "\n",
    "froot = './proseqSimulator'\n",
    "\n",
    "df = pd.read_csv(froot + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01a0ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = 'ACGT'\n",
    "NALPH = len(ALPHABET)\n",
    "INVALPH = [-1] * ord('Z')\n",
    "for i, char in enumerate(ALPHABET):\n",
    "    INVALPH[ord(char)] = i\n",
    "        \n",
    "def seq_to_one_hot(seq):\n",
    "    seqlen = len(seq)\n",
    "    res = np.zeros(NALPH * seqlen, dtype=np.uint8)    \n",
    "    arr = np.array(list(seq))\n",
    "    for j, c in enumerate(arr):\n",
    "        res[NALPH*j + INVALPH[ord(c)]] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c6f71a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to X,Y pairs representing single-column counts (Y) \n",
    "# and corresponding centered 50bp segments of the sequence (X)\n",
    "stride = 10\n",
    "featlen = 50\n",
    "offset = math.ceil(featlen/2)\n",
    "seqlen = len(df['seq'][0])\n",
    "centidx = range(offset, seqlen-offset, stride)\n",
    "\n",
    "j = 0\n",
    "y = np.zeros(len(centidx) * len(df),dtype=np.int16)\n",
    "x = np.zeros((len(centidx)*len(df),4*featlen),dtype=np.uint8)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    allcounts = np.array(df['readCounts'][i].strip('[]').split(),dtype=np.int16)  # better way?\n",
    "    allseq = df['seq'][i]\n",
    "\n",
    "    for r in centidx:\n",
    "        y[j] = allcounts[r]\n",
    "        x[j,:] = seq_to_one_hot(allseq[r-offset:r-offset+featlen])\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8c60f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set them up as tensors\n",
    "xtens = torch.Tensor(x)\n",
    "ytens = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27f7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, test, and validation sets\n",
    "allset = TensorDataset(xtens, ytens)\n",
    "trnset, valset, tstset = td.random_split(allset, [0.5,0.25,0.25])\n",
    "\n",
    "# set up data loaders\n",
    "trndl = DataLoader(trnset, batch_size=64, shuffle=True)\n",
    "tstdl = DataLoader(tstset, batch_size=64, shuffle=True)\n",
    "valdl = DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2404f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv1d(1, 8, kernel_size=(10,), stride=(1,), padding=(10,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=10, stride=10, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=168, out_features=1, bias=True)\n",
      ")\n",
      "torch.Size([64, 1])\n",
      "Number of parameters: 257\n"
     ]
    }
   ],
   "source": [
    "# set up the model\n",
    "import torch.nn as nn\n",
    "\n",
    "# this model is slightly adapted from an image-processing CNN in \n",
    "#\"Machine Learning with PyTorch and Scikit-Learn\", Raschka et al.\n",
    "model = nn.Sequential()\n",
    "model.add_module(\n",
    "    'conv1',\n",
    "    nn.Conv1d(\n",
    "        in_channels=1, out_channels=8,\n",
    "        kernel_size=10, padding=10\n",
    "    )\n",
    ")\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool1d(kernel_size=10))\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "model.add_module('linear', nn.Linear(168,1))\n",
    "\n",
    "# check model\n",
    "print(model)\n",
    "\n",
    "x = torch.ones((64,1,200))\n",
    "print(model(x).shape)\n",
    "nparm = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \" + str(nparm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c97e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            # have to fix dimensionality\n",
    "            x_batch_sz = x_batch.size()[0]\n",
    "            x_batch_re = torch.reshape(x_batch, (x_batch_sz, 1, 200))\n",
    "            pred = model(x_batch_re)    \n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            \n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                # have to fix dimensionality\n",
    "                x_batch_sz = x_batch.size()[0]\n",
    "                x_batch_re = torch.reshape(x_batch, (x_batch_sz, 1, 200))\n",
    "                pred = model(x_batch_re)    \n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0)\n",
    "                \n",
    "            loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "            \n",
    "        print(f'Epoch {epoch+1} trn_loss: '\n",
    "              f'{loss_hist_train[epoch]:.4f} val_loss: '\n",
    "              f'{loss_hist_valid[epoch]:.4f}')\n",
    "        \n",
    "    return loss_hist_train, loss_hist_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6daa8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 1 trn_loss: 1.1332 val_loss: 1.1484\n",
      "Epoch 2\n",
      "Epoch 2 trn_loss: 1.1194 val_loss: 1.1484\n",
      "Epoch 3\n",
      "Epoch 3 trn_loss: 1.1184 val_loss: 1.1496\n",
      "Epoch 4\n",
      "Epoch 4 trn_loss: 1.1176 val_loss: 1.1444\n",
      "Epoch 5\n",
      "Epoch 5 trn_loss: 1.1170 val_loss: 1.1448\n",
      "Epoch 6\n",
      "Epoch 6 trn_loss: 1.1166 val_loss: 1.1479\n",
      "Epoch 7\n",
      "Epoch 7 trn_loss: 1.1163 val_loss: 1.1444\n",
      "Epoch 8\n",
      "Epoch 8 trn_loss: 1.1162 val_loss: 1.1471\n",
      "Epoch 9\n",
      "Epoch 9 trn_loss: 1.1163 val_loss: 1.1442\n",
      "Epoch 10\n",
      "Epoch 10 trn_loss: 1.1157 val_loss: 1.1432\n",
      "Epoch 11\n",
      "Epoch 11 trn_loss: 1.1157 val_loss: 1.1434\n",
      "Epoch 12\n",
      "Epoch 12 trn_loss: 1.1159 val_loss: 1.1484\n",
      "Epoch 13\n",
      "Epoch 13 trn_loss: 1.1157 val_loss: 1.1473\n",
      "Epoch 14\n",
      "Epoch 14 trn_loss: 1.1154 val_loss: 1.1441\n",
      "Epoch 15\n",
      "Epoch 15 trn_loss: 1.1158 val_loss: 1.1437\n",
      "Epoch 16\n",
      "Epoch 16 trn_loss: 1.1156 val_loss: 1.1432\n",
      "Epoch 17\n",
      "Epoch 17 trn_loss: 1.1150 val_loss: 1.1430\n",
      "Epoch 18\n",
      "Epoch 18 trn_loss: 1.1150 val_loss: 1.1426\n",
      "Epoch 19\n",
      "Epoch 19 trn_loss: 1.1152 val_loss: 1.1426\n",
      "Epoch 20\n",
      "Epoch 20 trn_loss: 1.1150 val_loss: 1.1459\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, trndl, valdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b875758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
